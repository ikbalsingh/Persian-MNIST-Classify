{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ikbal\\\\Desktop\\\\projects\\\\flower-classification'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# model = tf.keras.applications.MobileNetV2(\n",
    "#             input_shape=[224, 224, 3],\n",
    "#             weights=\"imagenet\",\n",
    "#             include_top=False\n",
    "#         )\n",
    "\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# flatten_in = tf.keras.layers.Flatten()(model.output)\n",
    "# prediction = tf.keras.layers.Dense(\n",
    "#     units=17,\n",
    "#     activation=\"softmax\"\n",
    "# )(flatten_in)\n",
    "\n",
    "# full_model = tf.keras.models.Model(\n",
    "#     inputs=model.input,\n",
    "#     outputs=prediction\n",
    "# )\n",
    "\n",
    "# full_model.compile(\n",
    "#     optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "#     loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "#     metrics=[\"accuracy\"]\n",
    "# )\n",
    "\n",
    "# full_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 111, 111, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 26, 26, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 86528)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               11075712  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11169605 (42.61 MB)\n",
      "Trainable params: 11169605 (42.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the 3-layer CNN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=5, activation='softmax')  # Assuming 17 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[224, 224]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[224, 224, 3][: -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 5 classes.\n",
      "Found 4000 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "training_data = os.path.join(\"artifacts/data_ingestion\", \"flower_images\")\n",
    "\n",
    "datagenerator_kwargs = dict(\n",
    "    rescale = 1./255,\n",
    "    validation_split=0.20\n",
    ")\n",
    "\n",
    "dataflow_kwargs = dict(\n",
    "    target_size=[224, 224, 3][:-1],\n",
    "    batch_size=16,\n",
    "    interpolation=\"bilinear\"\n",
    ")\n",
    "\n",
    "valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    **datagenerator_kwargs\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagenerator.flow_from_directory(\n",
    "    directory=training_data,\n",
    "    subset=\"validation\",\n",
    "    shuffle=False,\n",
    "    **dataflow_kwargs\n",
    ")\n",
    "\n",
    "train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    **datagenerator_kwargs\n",
    ")\n",
    "\n",
    "\n",
    "train_generator = train_datagenerator.flow_from_directory(\n",
    "    directory=training_data,\n",
    "    subset=\"training\",\n",
    "    shuffle=True,\n",
    "    **dataflow_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Lilly', 1: 'Lotus', 2: 'Orchid', 3: 'Sunflower', 4: 'Tulip'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_dict = {v: k for k, v in train_generator.class_indices.items()} \n",
    "reverse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n",
      "Epoch 1/5\n",
      "250/250 [==============================] - 654s 3s/step - loss: 1.4360 - accuracy: 0.3725 - val_loss: 1.2774 - val_accuracy: 0.4748\n",
      "Epoch 2/5\n",
      "161/250 [==================>...........] - ETA: 2:34 - loss: 1.2974 - accuracy: 0.4488"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "    device = '/device:GPU:0'  # Use the first GPU\n",
    "else:\n",
    "    print('No GPU found')\n",
    "    device = '/device:CPU:0'\n",
    "\n",
    "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
    "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
    "with tf.device(device):\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        epochs=5,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_steps=validation_steps,\n",
    "        validation_data=valid_generator,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step\n",
      "Crocus\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "imagename = \"artifacts/data_ingestion/flowe_images/Daffodil/image_0006.jpg\"\n",
    "test_image = image.load_img(imagename, target_size = (224,224, 3))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = np.argmax(full_model.predict(test_image), axis=1)\n",
    "print(reverse_dict[result[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x221a5339490>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
